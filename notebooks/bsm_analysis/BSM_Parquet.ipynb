{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b4b030",
   "metadata": {},
   "source": [
    "# BSM Parquet Analysis\n",
    "\n",
    "This notebook processes and analyzes Basic Safety Message (BSM) data stored in Parquet files. It demonstrates how to load, filter, decode, and visualize BSM messages, focusing on specific geohashes and vehicle movement over time.\n",
    "\n",
    "The workflow includes:\n",
    "- Loading and concatenating Parquet files\n",
    "- Time and geohash-based grouping\n",
    "- Focusing on specific geohashes\n",
    "- Decoding BSM messages using a C binary\n",
    "- Extracting BSM IDs and timestamps\n",
    "- Identifying repeated BSMs\n",
    "- Visualizing vehicle movement with Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d572cc",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "This cell imports essential Python libraries for data manipulation, visualization, and file handling, including pandas, matplotlib, seaborn, pyarrow, and os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyarrow.parquet as pq\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa6c76",
   "metadata": {},
   "source": [
    "## Load and Concatenate Parquet Files\n",
    "This cell locates all Parquet files in the specified directory, reads them into pandas DataFrames, concatenates them into a single DataFrame, and displays basic information about the combined data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Set the directory containing your parquet files\n",
    "parquet_dir = \"./parquet\"  # Update if needed\n",
    "\n",
    "# Find all .parquet files in the directory\n",
    "parquet_files = sorted(glob.glob(os.path.join(parquet_dir, \"*.parquet\")))\n",
    "\n",
    "print(f\"Found {len(parquet_files)} Parquet files.\")\n",
    "\n",
    "# Read and concatenate all parquet files into a single DataFrame\n",
    "if parquet_files:\n",
    "\tdf_all = pd.concat([pd.read_parquet(f) for f in parquet_files], ignore_index=True)\n",
    "\t# Show basic info\n",
    "\tdf_all.info()\n",
    "\tdf_all.head()\n",
    "else:\n",
    "\tprint(\"No Parquet files found in the directory.\")\n",
    "\tdf_all = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd45d1f",
   "metadata": {},
   "source": [
    "## Group by Time and Geohash\n",
    "This cell converts timestamps to datetime, buckets them by minute, groups the data by time bucket and geohash, and displays the largest groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ff391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert float timestamp to datetime\n",
    "df_all['Time'] = pd.to_datetime(df_all['TimeStamp'], unit='s')\n",
    "\n",
    "# Optional: round to nearest 1 minute\n",
    "df_all['TimeBucket'] = df_all['Time'].dt.floor('1MIN')  # Change to '1min', '30s' etc. as needed\n",
    "\n",
    "grouped = df_all.groupby(['TimeBucket', 'Geohash'])\n",
    "\n",
    "group_sizes = grouped.size().reset_index(name='Count')\n",
    "group_sizes.sort_values('Count', ascending=False).head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9769639b",
   "metadata": {},
   "source": [
    "## Filter for Focus Geohashes\n",
    "This cell filters the DataFrame to include only rows with geohashes of interest, sorts the results for readability, and displays message counts per geohash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18590bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_geohashes = ['9tbq2v6h', '9tbq8b1c', '9tbq8c1g', '9tbq8ccy']\n",
    "df_focus = df_all[df_all['Geohash'].isin(focus_geohashes)]\n",
    "\n",
    "print(\"Message count per geohash:\")\n",
    "print(df_focus['Geohash'].value_counts())\n",
    "\n",
    "# Sort by geohash and time for better readability\n",
    "df_focus_sorted = df_focus.sort_values(by=[\"Geohash\", \"Time\"])\n",
    "df_focus_sorted.reset_index(drop=True, inplace=True)\n",
    "df_focus_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea79c59",
   "metadata": {},
   "source": [
    "## Decode BSM Messages Using C Binary\n",
    "This cell locates the C binary decoder, prepares the focus DataFrame, converts message bytes to hex, and decodes each BSM message using the external decoder. It also prints a few decoded outputs for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Detect repo root and set decoder path RELATIVE to repo root\n",
    "notebook_dir = Path.cwd()\n",
    "repo_root = None\n",
    "\n",
    "# Traverse up to find .git as marker for root\n",
    "for parent in notebook_dir.parents:\n",
    "    if (parent / \".git\").exists():\n",
    "        repo_root = parent\n",
    "        break\n",
    "if repo_root is None:\n",
    "    repo_root = notebook_dir  # fallback if not using git\n",
    "\n",
    "DECODER_PATH = repo_root / \"libsm/b2v-libsm/build/bin/decodeToJER\"\n",
    "print(\"Detected repo root:\", repo_root)\n",
    "print(\"Decoder Path:\", DECODER_PATH)\n",
    "if not DECODER_PATH.exists():\n",
    "    raise FileNotFoundError(f\"decodeToJER not found at {DECODER_PATH}\")\n",
    "\n",
    "# 2. Focused geohashes\n",
    "focus_geohashes = ['9tbq2v6h', '9tbq8b1c', '9tbq8c1g', '9tbq8ccy']\n",
    "df_focus = df_all[df_all['Geohash'].isin(focus_geohashes)].copy()\n",
    "print(\"BSMs in focus:\", len(df_focus))\n",
    "\n",
    "# 3. Convert mf_bytes to hex\n",
    "def mf_bytes_to_hex(val):\n",
    "    if isinstance(val, (bytes, bytearray)):\n",
    "        return val.hex()\n",
    "    if isinstance(val, str) and val.startswith(\"b'\"):  # as string repr\n",
    "        return eval(val).hex()\n",
    "    return None\n",
    "\n",
    "df_focus[\"mf_hex\"] = df_focus[\"mf_bytes\"].apply(mf_bytes_to_hex)\n",
    "\n",
    "# 4. Decode each BSM using the C binary\n",
    "def decode_bsm_hex(hex_str):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [str(DECODER_PATH), \"-i\", hex_str],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            check=True,\n",
    "            text=True,\n",
    "            timeout=3,\n",
    "        )\n",
    "        return result.stdout\n",
    "    except Exception as e:\n",
    "        print(f\"[DecodeError] {e}\")\n",
    "        return None\n",
    "\n",
    "df_focus[\"jer\"] = df_focus[\"mf_hex\"].apply(decode_bsm_hex)\n",
    "print(\"Decoded BSMs:\", df_focus['jer'].notnull().sum())\n",
    "\n",
    "# 5. (Optional) Show a few decoded outputs for inspection\n",
    "for jer in df_focus[\"jer\"].dropna().head(3):\n",
    "    print(jer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e524582",
   "metadata": {},
   "source": [
    "## Extract BSM ID and Identify Repeated Messages\n",
    "This cell parses the decoded JER output to extract BSM IDs and secMark values, sorts by ID and timestamp, computes time differences between consecutive messages with the same ID, and identifies BSMs that are repeated within a short time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 1. Extract id and secMark from the decoded JER string (for each row)\n",
    "def extract_id_secmark(jer_str):\n",
    "    try:\n",
    "        jer = json.loads(jer_str)\n",
    "        bsm = jer[\"value\"][\"BasicSafetyMessage\"][\"coreData\"]\n",
    "        return bsm.get(\"id\"), bsm.get(\"secMark\")\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "df_focus[[\"bsm_id\", \"bsm_secMark\"]] = df_focus[\"jer\"].apply(lambda x: pd.Series(extract_id_secmark(x)))\n",
    "\n",
    "# 2. Check which BSMs have the same id and nearby timestamps (TimeStamp or secMark)\n",
    "# Sort for easier comparison\n",
    "df_focus_sorted = df_focus.sort_values([\"bsm_id\", \"TimeStamp\"])\n",
    "\n",
    "# Compute time difference (in seconds) to previous message with same id\n",
    "df_focus_sorted[\"prev_TimeStamp\"] = df_focus_sorted.groupby(\"bsm_id\")[\"TimeStamp\"].shift(1)\n",
    "df_focus_sorted[\"dt_sec\"] = df_focus_sorted[\"TimeStamp\"] - df_focus_sorted[\"prev_TimeStamp\"]\n",
    "\n",
    "# Show BSMs with dt_sec < threshold (e.g., 2 seconds)\n",
    "threshold = 2\n",
    "nearby = df_focus_sorted[df_focus_sorted[\"dt_sec\"].notnull() & (df_focus_sorted[\"dt_sec\"] < threshold)]\n",
    "\n",
    "print(f\"BSMs with repeated id within {threshold} seconds:\")\n",
    "display(nearby[[\"bsm_id\", \"TimeStamp\", \"dt_sec\", \"Geohash\", \"Latitude\", \"Longitude\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e79867",
   "metadata": {},
   "source": [
    "## Visualize BSM Movement by Vehicle ID\n",
    "This cell prepares the data for animation, then uses Plotly to create an animated map showing the movement of vehicles (by BSM ID) over time, with one frame per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Ensure Time is datetime and round/floor to seconds\n",
    "df_focus_sorted[\"Time\"] = pd.to_datetime(df_focus_sorted[\"Time\"])\n",
    "df_focus_sorted[\"Time_sec\"] = df_focus_sorted[\"Time\"].dt.floor(\"S\")\n",
    "\n",
    "# (Optional) Convert bsm_id to string for display\n",
    "df_focus_sorted[\"bsm_id\"] = df_focus_sorted[\"bsm_id\"].astype(str)\n",
    "\n",
    "# Sort by Time for animation\n",
    "df_anim = df_focus_sorted.sort_values(\"Time_sec\")\n",
    "\n",
    "fig = px.scatter_map(\n",
    "    df_anim,\n",
    "    lat=\"Latitude\",\n",
    "    lon=\"Longitude\",\n",
    "    color=\"bsm_id\",      # Color by vehicle\n",
    "    animation_frame=df_anim[\"Time_sec\"].dt.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    hover_name=\"bsm_id\",\n",
    "    zoom=12,\n",
    "    height=600,\n",
    "    map_style=\"open-street-map\"  # Same style as before\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"BSM Movement by Vehicle ID (Per Second)\",\n",
    "    margin={\"r\":0, \"t\":30, \"l\":0, \"b\":0},\n",
    ")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
